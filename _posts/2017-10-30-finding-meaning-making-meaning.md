---
inFeed: false
description: >-
  In anthropology we often speak of the notion of webs of significance or webs
  of meaning. In essence, an mostly according to anthropologist Clifford Geertz,
  we all belong to different webs of meaning that we are part of constructing
  and upholding. Text analysis is like looking for those webs in individual or
  corpuses (sp?) of text.
dateModified: '2017-10-30T01:05:39.687Z'
datePublished: '2017-10-30T01:05:40.100Z'
title: 'Finding meaning, making meaning with text analysis.'
author: []
publisher: {}
via: {}
sourcePath: _posts/2017-10-30-finding-meaning-making-meaning.md
hasPage: true
starred: false
datePublishedOriginal: '2017-10-30T01:03:24.069Z'
url: finding-meaning-making-meaning-with-text-analysis/index.html
_type: MediaObject

---
# Finding meaning, making meaning with text analysis.
![](https://the-grid-user-content.s3-us-west-2.amazonaws.com/cdd9eace-0f62-4fea-b10a-11b60234ba87.jpg)

In anthropology we often speak of the notion of webs of significance or webs of meaning. In essence, an mostly according to anthropologist Clifford Geertz, we all belong to different webs of meaning that we are part of constructing and upholding. Text analysis is like looking for those webs in individual or corpuses (sp?) of text.

In the readings for this section, I actually saw a couple of connections with code (the topic of our last section), most notably in Rockwell's article, "What is Text Analysis, Really?", when he writes about the creation of new texts as a result of the re-ordering of old ones to fit new narratives. The example he used was the bible, but I likened this to new programming languages, essentially taking parts of older and more established languages, and reconfiguring them to make new ones. With the advent of new text analysis tools, it is increasingly easier to find new ways of looking at texts and seeing patterns emerge that would otherwise be missed.

Another interesting phenomenon that arises from this, is that as content becomes increasingly digitized, with new content pretty much by default, there is a real interoperability to it, which makes it easier and easier to analyze with better and better tools. what i find wonderful about this is that suddenly text analysis becomes something that can be done at any time and therefore becomes more of a continuum rathe than discreet data points. Having said that, I am curious if there is much text analysis done on aggregated results of text analysis? what patterns would this meta analysis reveal, and would it align back to the original texts or become something on its own through iterations?

There is a dark path here however, in that the tools for analyzing the really big data sets are not very accessible to all researchers. If this is the case, it begs the question of whether current research that's based on this data is inherently biased towards the limits of the hypotheses that generated this data to begin with? I see this as problematic, given that we are then left to make correlations based on assumptions.

All in all though, it is comforting to know that since no one has yet figured out the definitive way to do text analysis, we are all still happily iterating and learning from each other about different ways of finding meaning in an ever-growing body of knowledge.